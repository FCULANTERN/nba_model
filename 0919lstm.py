# -*- coding: utf-8 -*-
"""0919lstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11lbnTdA7XHJrWlM-Wxkj_extzBPPImxq
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.layers import Dense, Dropout

data = pd.read_csv('final_data.csv')

"""
import pandas as pd

# 假設 data_sorted 是你已經排序好的資料
data_sorted = data.copy()

# 獲取所有數值型特徵列，排除 'playerid' 和 'gameid'
columns_to_exclude = ['playerid', 'gameid']
features_to_replace = data_sorted.select_dtypes(include=['float64', 'int64']).columns
features_to_replace = [col for col in features_to_replace if col not in columns_to_exclude]

# 從最後一行開始，往前尋找對應的playerid的上一場比賽
for i in range(len(data_sorted) - 1, -1, -1):
    current_player = data_sorted.loc[i, 'playerid']

    # 往前尋找是否有相同的 playerid
    found_previous = False
    for j in range(i - 1, -1, -1):
        if data_sorted.loc[j, 'playerid'] == current_player:
            # 找到上一場比賽，替換當前行的數據
            data_sorted.loc[i, features_to_replace] = data_sorted.loc[j, features_to_replace]
            found_previous = True
            break

    # 如果沒有找到前一場比賽，將當前行數據設為 0
    if not found_previous:
        data_sorted.loc[i, features_to_replace] = 0

# 查看結果
data_sorted.head()
"""

#grouped_data = pd.DataFrame(data_sorted)
#grouped_data.to_csv('/content/LookingFoward_data.csv', index=False)

data = pd.read_csv('LookingFoward_data.csv')

data.head()

from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import MinMaxScaler
# 標準化
scaler = MinMaxScaler()

# 主客場
data['home_basic'] = data['home_basic'].apply(lambda x: 1 if x == 'TRUE' else 0)
# 假设 'win' 列包含 'TRUE' 和 'FALSE' 字符串
data['win'] = data['win'].map({'TRUE': 1, 'FALSE': 0})

# 如果你要对所有包含 'TRUE' 和 'FALSE' 的列进行转换
bool_columns = data.columns[data.isin(['TRUE', 'FALSE']).any()]

# 对所有这些列进行转换
for col in bool_columns:
    data[col] = data[col].map({'TRUE': 1, 'FALSE': 0})

file_path = 'selected_columns_s.txt'

with open(file_path, 'r') as file:
    selected_columns = [line.strip() for line in file]

print(selected_columns)

# 依照gameid進行分組，每一組代表一場比賽
games = data.groupby('gameid')

playerids = data.groupby('playerid')

# 將每場比賽中的所有球員數據合併成一個特徵向量
X = []
y = []

for gameid, group in games:
    if len(group) != 30:  # 每場比賽最多有30位球員
        continue

    # 將每場比賽中的所有球員數據合併成一個特徵向量
    #game_features = group.drop(columns=['gameid', 'win', 'home_basic','date']).values.flatten(
    game_features = group[selected_columns].values.flatten()
    game_features = np.append(game_features, group['date'].iloc[0])
    game_features = np.append(game_features, group['win'].iloc[0])
    X.append(game_features)
    #y.append(group['win'].iloc[0])

X = np.array(X)

X = pd.DataFrame(X)
#X.to_csv('/content/X.csv', index=False)
# 根據日期的值對所有行進行排序
#X_sorted = X.sort_values(by=X.columns[1501], ascending=True)
# 顯示排序後的DataFrame
#X_sorted.head()

df = X.reset_index(drop=True)

df

df = pd.DataFrame(df)
df.to_csv('df.csv', index=False)

df = pd.read_csv('Transformed_DataFrame.csv')

df

# 找到"team"的位置
team_index = [i for i, col in enumerate(selected_columns) if "team" in col]

# 輸出結果
print(team_index)

# Access the column at index 1501
y = np.array(df.iloc[:, 1501])
# 勝負
y = np.where(y == 1, 1, 0)
y = to_categorical(y, 2)

Y = pd.DataFrame(y)

Y

df.drop(df.columns[1501], axis=1, inplace=True)

df

X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.3)
X_train_df = pd.DataFrame(X_train)
#X_train_df.to_csv('/content/X_trainA.csv', index=False)

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

dropout_rate = 0.2

# Reshape the input data correctly
X_train = X_train.reshape(X_train.shape[0], 1, 1501)  # (samples, time steps, features)
X_test = X_test.reshape(X_test.shape[0], 1, 1501)    # (samples, time steps, features)

my_model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(80, activation=tf.nn.tanh, return_sequences=True, input_shape=(1, 1501)), # Correct input shape
    tf.keras.layers.Dropout(dropout_rate),
    tf.keras.layers.LSTM(60, activation=tf.nn.tanh, return_sequences=True),
    tf.keras.layers.Dropout(dropout_rate),
    tf.keras.layers.LSTM(40, activation=tf.nn.tanh),
    tf.keras.layers.Dropout(dropout_rate),
    tf.keras.layers.Dense(20, activation=tf.nn.sigmoid),
    tf.keras.layers.Dropout(dropout_rate),
    tf.keras.layers.Dense(2, activation=tf.nn.softmax)
])

my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# 训练模型
my_model.fit(X_train, y_train, epochs=30, batch_size=32)

# 评估模型
loss, accuracy = my_model.evaluate(X_test, y_test, verbose=0)

# 函數：處理球隊 ID 並將結果存入 result_array
def process_player_ids1(player_ids, data, selected_columns):
    for player_id in player_ids:
        found = False
        for idx in range(len(data) - 1, -1, -1):  # 從最後一行開始
            if data.loc[idx, 'playerid'] == player_id:  # 找到對應的 player_id
                # 提取該行的特徵數據
                selected_data = data.loc[idx, selected_columns]
                # 存到結果陣列中
                result_array1.append(selected_data)
                found = True
                break  # 找到後跳出內部循環，進行下一個 player_id 的處理

        if not found:
            # 如果沒有找到該 player_id，填充一行全為 0 的數據
            zero_data = pd.Series([0] * len(selected_columns), index=selected_columns)
            result_array1.append(zero_data)

import pandas as pd
import numpy as np

# 創建一個存儲結果的新陣列
result_array1 = []
# 增加球員ID到15位
team1_player_ids1 = [1627759,1628369,201143,1628401,203935,203943,1629684,1627763,201933,1630573,1631120,1628382,1629662,1628436,1630202]
team2_player_ids1 = [202699,200782,203954,1630178,201935,1626149,1629001,1627863,1627777,1629680,1627788,1629003,1630194,1630531,0]



# 處理 team1_player_ids
process_player_ids1(team1_player_ids1, data, selected_columns)

# 處理 team2_player_ids
process_player_ids1(team2_player_ids1, data, selected_columns)

# 將結果轉換為 DataFrame 方便查看
result_df1 = pd.DataFrame(result_array1)
result_df1

feature_vector1 = result_df1.values.flatten()

feature_vector1 = np.append(feature_vector1,776)
# 將一維向量轉換為 DataFrame 的一行
flattened_df1 = pd.DataFrame([feature_vector1])

flattened_df1

flattened_df1 = scaler.fit_transform(flattened_df1)

input_vector1 = flattened_df1.reshape(1, 1, 1501)
predicted_class1 = my_model.predict(input_vector1)

# 打印預測的類別
print("Predicted class:", predicted_class1)

# 創建一個存儲結果的新陣列
result_array2 = []
# 函數：處理球隊 ID 並將結果存入 result_array
def process_player_ids_g(player_ids, data, selected_columns):
    for player_id in player_ids:
        found = False
        for idx in range(len(data) - 1, -1, -1):  # 從最後一行開始
            if data.loc[idx, 'playerid'] == player_id:  # 找到對應的 player_id
                # 提取該行的特徵數據
                selected_data = data.loc[idx, selected_columns]
                # 存到結果陣列中
                result_array2.append(selected_data)
                found = True
                break  # 找到後跳出內部循環，進行下一個 player_id 的處理

        if not found:
            # 如果沒有找到該 player_id，填充一行全為 0 的數據
            zero_data = pd.Series([0] * len(selected_columns), index=selected_columns)
            result_array2.append(zero_data)
# 增加球員ID到15位
team1_player_ids2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
team2_player_ids2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
#[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
# 處理 team1_player_ids
process_player_ids_g(team1_player_ids2, data, selected_columns)

# 處理 team2_player_ids
process_player_ids_g(team2_player_ids2, data, selected_columns)

result_df2 = pd.DataFrame(result_array2)
result_df2

feature_vector2 = result_df2.values.flatten()
feature_vector2 = np.append(feature_vector2,444)
# 將一維向量轉換為 DataFrame 的一行
flattened_df2 = pd.DataFrame([feature_vector2])
flattened_df2

#標準化
flattened_df2 = scaler.fit_transform(flattened_df2)
input_vector2 = flattened_df2.reshape(1, 1, 1501)
input_vector2

predicted_class2 = my_model.predict(input_vector2)

# 打印預測的類別
print("Predicted class:", predicted_class2)

predicted_class2